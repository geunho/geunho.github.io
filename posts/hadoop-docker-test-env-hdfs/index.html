<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="referrer" content="no-referrer">
    

    
      <link href='https://fonts.googleapis.com/css?family=Open+Sans:400|Old+Standard+TT:400' rel='stylesheet' type='text/css'>
    

    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

    <title>
      
      
         Docker로 Hadoop 테스트 환경 구축하기 - HDFS 
      
    </title>
    <link rel="canonical" href="https://blog.geunho.dev/posts/hadoop-docker-test-env-hdfs/">

    <style>
  * {
    border:0;
    font:inherit;
    font-size:100%;
    vertical-align:baseline;
    margin:0;
    padding:0;
    color: black;
    text-decoration-skip: ink;
  }

  body {
    font-family:'Open Sans', 'Myriad Pro', Myriad, sans-serif;
    font-size:17px;
    line-height:160%;
    color:#1d1313;
    max-width:700px;
    margin:auto;
  }

  .footnotes {
    margin: 30px 0 40px 0;
  }
  sup.footnote-ref {
    font-size: 0.85em;
    vertical-align: top;
    position: relative;
    top: -0.5em;
  }

  footer {
    font-size: x-small;
    letter-spacing: 0.5px;
  }

  p {
    margin: 20px 0;
  }

  a img {
    border:none;
  }

  img {
    margin: 10px auto 10px auto;
    max-width: 75%;
    display: block;
  }

  .left-justify {
    float: left;
  }

  .right-justify {
    float:right;
  }

  pre, code {
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
    background-color: #f7f7f7;
  }

  code {
    font-size: 12px;
    padding: 4px;
  }

  pre {
    margin-top: 0;
    margin-bottom: 16px;
    word-wrap: normal;
    padding: 16px;
    overflow: auto;
    font-size: 85%;
    line-height: 1.45;
  }

  pre>code {
    padding: 0;
    margin: 0;
    font-size: 100%;
    word-break: normal;
    white-space: pre;
    background: transparent;
    border: 0;
  }

  pre code {
    display: inline;
    max-width: auto;
    padding: 0;
    margin: 0;
    overflow: visible;
    line-height: inherit;
    word-wrap: normal;
    background-color: transparent;
    border: 0;
  }

  pre code::before,
  pre code::after {
    content: normal;
  }

  em,q,em,dfn {
    font-style:italic;
  }

  .sans,html .gist .gist-file .gist-meta {
    font-family:"Open Sans","Myriad Pro",Myriad,sans-serif;
  }

  .mono,pre,code,tt,p code,li code {
    font-family:Menlo,Monaco,"Andale Mono","lucida console","Courier New",monospace;
  }

  .heading,.serif,h1,h2,h3 {
    font-family:"Old Standard TT",serif;
  }

  strong {
    font-weight:600;
  }

  q:before {
    content:"\201C";
  }

  q:after {
    content:"\201D";
  }

  del,s {
    text-decoration:line-through;
  }

  blockquote {
    font-family:"Old Standard TT",serif;
    text-align:center;
    padding:50px;
  }

  blockquote p {
    display:inline-block;
    font-style:italic;
  }

  blockquote:before,blockquote:after {
    font-family:"Old Standard TT",serif;
    content:'\201C';
    font-size:35px;
    color:#403c3b;
  }

  blockquote:after {
    content:'\201D';
  }

  hr {
    width:40%;
    height: 1px;
    background:#403c3b;
    margin: 25px auto;
  }

  h1 {
    font-size:35px;
  }

  h2 {
    font-size:28px;
  }

  h3 {
    font-size:22px;
    margin-top:18px;
  }

  h1 a,h2 a,h3 a {
    text-decoration:none;
  }

  h1,h2 {
    margin-top:28px;
  }

  #sub-header, time {
    color:#403c3b;
    font-size:13px;
  }

  #sub-header {
    margin: 0 4px;
  }

  #nav h1 a {
    font-size:35px;
    color:#1d1313;
    line-height:120%;
  }

  .posts_listing a,#nav a {
    text-decoration: none;
  }

  li {
    margin-left: 20px;
  }

  ul li {
    margin-left: 5px;
  }

  ul li {
    list-style-type: none;
  }

  ul li:before {
    content:"\2022 \0020";
  }

  ul li ul li:before {
    content:"\2043 \0020";
  }

  #nav ul li:before, .posts_listing li:before {
    content:'';
    margin-right:0;
  }

  #content {
    text-align:left;
    width:100%;
    font-size:15px;
    padding:60px 0 80px;
  }

  #content h1,#content h2 {
    margin-bottom:5px;
  }

  #content h2 {
    font-size:25px;
  }

  #content .entry-content {
    margin-top:15px;
  }

  #content time {
    margin-left:3px;
  }

  #content h1 {
    font-size:30px;
  }

  .highlight {
    margin: 10px 0;
  }

  .posts_listing {
    margin:0 0 50px;
  }

  .posts_listing li {
    margin:0 0 25px 15px;
  }

  .posts_listing li a:hover,#nav a:hover {
    text-decoration: underline;
  }

  #nav {
    text-align:center;
    position:static;
    margin-top:60px;
  }

  #nav ul {
    display: table;
    margin: 8px auto 0 auto;
  }

  #nav li {
    list-style-type:none;
    display:table-cell;
    font-size:15px;
    padding: 0 20px;
  }

  #links {
    margin: 50px 0 0 0;
  }

  #links :nth-child(2) {
    float:right;
  }

  img.avatar {
    border-radius: 50%;
    width: 300px;
  }

   
  .social_id {
    color:#9b9b9b; 
    font-size:10px;
    text-align:center;
  }
  .social-icons {
    display: flex;
    justify-content: center;
  }
  .social-icons__icon {
    width: 1.5rem;
    height: 1.5rem;
    background-size: contain;
    background-repeat: no-repeat;
  }
  
  .social-icons__icon--linkedin {
    background-image: url(/icons/linkedin.svg);
    margin-right: 2rem;    
  }
  .social-icons__icon--github {
    background-image: url(/icons/github.svg);
    margin-right: 2rem; 
  }
  .social-icons__icon--gmail {
    background-image: url(/icons/gmail.svg);
  }

  .rss-icon {
    display: flex;
    width: 1.2rem;
    height: 1.2rem;
    background-size: contain;
    background-repeat: no-repeat;
    background-image: url(/icons/rss.svg);
  }

  #not-found {
    display: flex;
  }
  .not-found__icon--docker {
    width: 1.4rem;
    height: 1.4rem;
    margin-right: 0.5em;
    background-size: contain;
    background-repeat: no-repeat;
    background-image: url(/icons/docker.svg);
  }

  nav#TableOfContents {
    margin: 20px 0 50px 0;
  }

  @media (max-width: 750px) {
    body {
      padding-left:20px;
      padding-right:20px;
    }

    img {
      max-width: 80%;
    }

    #nav h1 a {
      font-size:28px;
    }

    #nav li {
      font-size:13px;
      padding: 0 15px;
    }

    #content {
      margin-top:0;
      padding-top:50px;
      font-size:14px;
    }

    #content h1 {
      font-size:25px;
    }

    #content h2 {
      font-size:22px;
    }

    .posts_listing li div {
      font-size:12px;
    }
  }

  @media (max-width: 400px) {
    body {
      padding-left:20px;
      padding-right:20px;
    }

    img {
      max-width: 100%;
    }

    #nav h1 a {
      font-size:22px;
    }

    #nav li {
      font-size:12px;
      padding: 0 10px;
    }

    #content {
      margin-top:0;
      padding-top:20px;
      font-size:12px;
    }

    #content h1 {
      font-size:20px;
    }

    #content h2 {
      font-size:18px;
    }

    .posts_listing li div{
      font-size:12px;
    }

    img.avatar {
      border-radius: 50%;
      width: 170px;
    }
  }
</style>


    
  </head>

  <body>
    <section id=nav>
      <h1><a href="/">Blog · 김근호(Kim, Geunho)</a></h1>
      <ul>
        
          <li><a href="/about">About</a></li>
        
          <li><a href="/posts">Posts</a></li>
        
          <li><a href="/thoughts">Thoughts</a></li>
        
          <li><a href="/til">TIL</a></li>
        
        <a class="rss-icon" href="/index.xml"></a>
      </ul>
    </section>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-146312497-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>




<section id="content">
  <h1> Docker로 Hadoop 테스트 환경 구축하기 - HDFS </h1>

  
    <div id="sub-header">
      28 August 2019 · 8 minutes read
    </div>
  

  <nav id="TableOfContents">
  <ul>
    <li><a href="#base">Base</a></li>
    <li><a href="#namenode">NameNode</a></li>
    <li><a href="#datanode">DataNode</a></li>
    <li><a href="#proxy">Proxy</a></li>
  </ul>
</nav>

  <div class="entry-content">
    <h1 id="docker와-테스트-환경">Docker와 테스트 환경</h1>
<p>Docker는 애플리케이션을 컨테이너화해서 이미지로 만들어 배치하고 실행할 수 있는 환경을 제공하는 컨테이너 도구<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>이다.<br>
격리된 파일 시스템을 갖는 컨테이너 특성 덕분에, 운영 환경에 대한 프로비져닝 뿐만 아니라 Docker가 설치된 환경에서 컨테이너화된 애플리케이션을 즉시 구동시켜서 테스트할 수 있는 환경을 구성하는데에도 유용하게 쓰인다.</p>
<p>오픈소스를 포함한 다양한 애플리케이션을 로컬 환경에 설치하고 구성하면서 테스트하다보면(주로 개발자의 노트북), 어느새 로컬 환경은 지저분해지고 몇 해 전에 설치한 애플리케이션이 자동 재시작되어 리소스를 점유하게 된다. 환경 설정 파일은 언제 어떻게 바꿨는지도 모른다. VM 환경으로 OS를 완전히 격리시켜 구성하자니 구동하는데 시간이 오래 걸리고 구동한 이후 점유하는 리소스가 노트북이 감당하기에는 참 크다.</p>
<p>Docker는 이런 환경에서 최적의 도구이다. 컨테이너를 어떻게 구성할지 애플리케이션마다 설정 파일을 생성하고, 서로 상호작용하는 애플리케이션인 경우 다시 실행과 관련된 설정 파일을 생성해서 여러 개의 애플리케이션을 순식간에 실행하고 다시 종료시킬 수 있다.</p>
<p>이 포스트에서는 Hadoop HDFS를 Docker로 컨테이너화 헤서 로컬에 테스트 환경으로 구성하는 방법을 설명한다.</p>
<!-- raw HTML omitted -->
<h1 id="hdfs">HDFS</h1>
<p>하둡 분산 파일 시스템(HDFS)은 마스터 노드인 <a href="/posts/hadoop-namenode">NameNode</a>와 워커 노드인 <a href="/posts/hadoop-datanode">DataNode</a>로 이루어져있다. 각각 JVM 위에서 동작하는 자바 애플리케이션으로, 두 애플리케이션만 동작을 하면 HDFS를 구성해서 읽고 쓸 수 있다.<br>
실행 환경은 일반적은 GNU/Linux 그리고 Windows 환경을 지원하며, Hadoop 2.7~2.x<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> 버전은 Java 7, 8을 지원한다.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
<p>클라이언트에서 각 애플리케이션과 직접 통신하는 포트 정보는 다음 표와 같다.</p>
<table>
<thead>
<tr>
<th>애플리케이션   </th>
<th>기본포트   </th>
<th>프로토콜   </th>
<th>상세설명</th>
<th>관련 설정 항목</th>
</tr>
</thead>
<tbody>
<tr>
<td>NameNode</td>
<td>50070</td>
<td>HTTP</td>
<td>HDFS 상태 및 파일 시스템 조회용 Web UI  </td>
<td><code>dfs.http.address</code></td>
</tr>
<tr>
<td></td>
<td>9000</td>
<td>IPC</td>
<td>파일 시스템 메타데이터 관련 작업용</td>
<td><code>fs.defaultFS</code></td>
</tr>
<tr>
<td>DataNode</td>
<td>50075</td>
<td>HTTP</td>
<td>상태 및 로그 조회용 Web UI</td>
<td><code>dfs.datanode.http.address</code></td>
</tr>
<tr>
<td></td>
<td>50010</td>
<td>TCP</td>
<td>데이터 전송</td>
<td><code>dfs.datanode.address</code></td>
</tr>
<tr>
<td><em>표 1. 클라이언트에서 HDFS와 직접 통신할 때 사용하는 포트 정보</em></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>이 자료들을 가지고 이제 본격적으로 Docker 컨테이너화를 진행해보자.</p>
<!-- raw HTML omitted -->
<h1 id="dockerize">Dockerize</h1>
<p>애플리케이션을 Docker에서 사용하는 설정 파일인 <code>Dockerfile</code> 양식에 맞게 구성한다. 이 설정 파일이 있으면 Docker 이미지 빌드가 가능하고, 생성한 이미지를 어디에서든 당겨와서(pull) 실행할 수 있다.</p>
<p>사실 이미지를 생성하는 것은 이 설정 파일 없이 직접 기반이 되는 OS 이미지로부터 컨테이너를 실행해서 쉘로 접속, 필요한 작업을 하고 이미지를 커밋해도 된다.<br>
하지만 이 방식은 다음과 같은 문제점이 있다:</p>
<ul>
<li>이미지가 어떻게 생성되었는지 기록이 남지 않음</li>
<li>따라서 작업한 내용을 다시 되돌리거나, 몇 가지 설정을 변경해서 새로운 이미지를 생성하기 어려움</li>
<li>그리고 생성된 이미지를 신뢰하기 어려움. 따라서 다른 사람과 공유하는데에도 적합하지 않음</li>
</ul>
<p>블록을 쌓아 올리듯 이미지를 만드는 Docker 세계에서는, 처음에는 조금 번거로워 보이더라도 <code>Dockerfile</code>로 이미지를 만드는 것에 익숙해지는 것이 좋다.</p>
<h2 id="base">Base</h2>
<p>NameNode 이미지를 만들기 전에, 먼저 각 컴포넌트의 밑바탕이 되는 이미지를 구성한다. 밑바탕 이미지는 다음과 같은 내용을 포함헤야 할 것이다.</p>
<ul>
<li>Hadoop binary</li>
<li>Java</li>
<li>Common configurations</li>
</ul>
<p>여기에서는 현재 2019년 8월 기준 Hadoop 2버전의 최신 버전인 2.9.2 버전을 사용했다. Hadoop 2는 Java 7 이상을 지원하므로 Java 8을 선택했다. 마지막으로 공용 설정은 core-site.xml, hdfs-site.xml을 포함하도록 구성할 것이다.</p>
<p>먼저 다음과 같은 디렉토리 구조로 폴더와 파일을 생성한다.</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback">.
└── hadoop
    ├── base
    │   ├── Dockerfile
    │   └── core-site.xml
    ├── namenode
    │   ├── Dockerfile
    │   ├── hdfs-site.xml
    │   └── start.sh
    └── datanode
        ├── Dockerfile
        ├── hdfs-site.xml
        └── start.sh
</code></pre></div><p>hadoop의 하위 폴더인 base, namenode, 그리고 datanode 폴더와 그 하위에 다시 위치한 개별 Dockerfile은 각 항목이 이미지로 빌드될 것임을 보여준다.</p>
<p><code>baes/Dockerfile</code>의 내용을 다음과 같이 작성한다.</p>
<div class="highlight"><pre class="chroma"><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># 기반이 되는 이미지를 설정. 여기서는 ubuntu 18 기반인 zulu의 openjdk 8버전을 선택</span><span class="err">
</span><span class="err"></span><span class="k">FROM</span><span class="s"> azul/zulu-openjdk:8</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># 바이너리를 내려받기 위해 설치</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> apt-get update <span class="o">&amp;&amp;</span> apt-get install -y curl <span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">ENV</span> <span class="nv">HADOOP_VERSION</span><span class="o">=</span><span class="m">2</span>.9.2<span class="err">
</span><span class="err"></span><span class="k">ENV</span> <span class="nv">HADOOP_URL</span><span class="o">=</span>http://mirror.apache-kr.org/hadoop/common/hadoop-<span class="nv">$HADOOP_VERSION</span>/hadoop-<span class="nv">$HADOOP_VERSION</span>.tar.gz<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Hadoop 2.9.2 버전을 내려받고 /opt/hadoop에 압축 해제</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> curl -fSL <span class="s2">&#34;</span><span class="nv">$HADOOP_URL</span><span class="s2">&#34;</span> -o /tmp/hadoop.tar.gz <span class="se">\
</span><span class="se"></span>    <span class="o">&amp;&amp;</span> tar -xvf /tmp/hadoop.tar.gz -C /opt/ <span class="se">\
</span><span class="se"></span>    <span class="o">&amp;&amp;</span> rm /tmp/hadoop.tar.gz<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># 데이터 디렉토리 생성 및 설정 폴더의 심볼릭 링크 생성</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> ln -s /opt/hadoop-<span class="nv">$HADOOP_VERSION</span> /opt/hadoop <span class="se">\
</span><span class="se"></span>    <span class="o">&amp;&amp;</span> mkdir /opt/hadoop/dfs <span class="se">\
</span><span class="se"></span>    <span class="o">&amp;&amp;</span> ln -s /opt/hadoop-<span class="nv">$HADOOP_VERSION</span>/etc/hadoop /etc/hadoop <span class="se">\
</span><span class="se"></span>    <span class="o">&amp;&amp;</span> rm -rf /opt/hadoop/share/doc<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># 로컬의 core-site.xml 파일을 복제</span><span class="err">
</span><span class="err"></span><span class="k">ADD</span> core-site.xml /etc/hadoop/<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># 실행 환경에 필요한 환경 변수 등록</span><span class="err">
</span><span class="err"></span><span class="k">ENV</span> HADOOP_PREFIX /opt/hadoop<span class="err">
</span><span class="err"></span><span class="k">ENV</span> HADOOP_CONF_DIR /etc/hadoop<span class="err">
</span><span class="err"></span><span class="k">ENV</span> PATH <span class="nv">$HADOOP_PREFIX</span>/bin/:<span class="nv">$PATH</span><span class="err">
</span><span class="err"></span><span class="k">ENV</span> JAVA_HOME /usr/lib/jvm/zulu-8-amd64<span class="err">
</span></code></pre></div><p>기반 이미지인 <code>azul/zulu-openjdk:8</code>는 ubuntu 18 기반이라서 이미지 크기가 315MB로 꽤 크다.<br>
이 크기를 작게 줄이려고 alpine 기반으로 생성해서는 안된다. Hadoop은 일반적인 GNU/Linux 환경에서 동작할 수 있도록 개발되었기 때문이다.</p>
<p><code>base/core-site.xml</code>은 다음과 같이 작성한다.</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="cp">&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>hdfs://namenode:9000/<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;description&gt;</span>NameNode URI
    <span class="nt">&lt;/description&gt;</span>
  <span class="nt">&lt;/property&gt;</span>  
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div><p><code>fs.defaultFS</code> 설정은 NameNode 위치를 찾는 중요한 설정으로, DataNode 뿐만 아니라 각종 애플리케이션에서 NameNode에 파일 읽기/쓰기 요청을 할 때 사용되는 항목이다.<br>
URI의 호스트 이름이 <code>namenode</code>로 설정되었는데, NameNode 컨테이너의 호스트 이름을 <code>namenode</code>로 지정할 것이다.</p>
<p>이제 터미널에서 <code>base</code> 디렉토리로 이동해서 baes 이미지를 생성해보자.</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh"><span class="nb">cd</span> base
docker build -t hadoop-base:2.9.2 .
</code></pre></div><p>현재 위치한 폴더의 Dockerfile을 사용해서 docker 이미지를 빌드하겠다는 명령어이다. Dockerfile을 작성한대로 각 라인이 하나의 빌드 단계가 되어 명렁어를 실행하는 로그가 출력된다.</p>
<p>빌드가 완료되면 다음 명렁어로 로컬에 생성된 이미지를 확인할 수 있다.</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">docker images

REPOSITORY        TAG                 IMAGE ID            CREATED             SIZE
hadoop-base       2.9.2               fab79eab7d71        <span class="m">2</span> mins ago          1.2GB
</code></pre></div><p>이 이미지는 다음과 같은 이미지 계층 구조를 갖는다. 간단한 구조를 갖지만 이 base 이미지를 통해 모든 Hadoop 컴포넌트의 기반으로 사용할 수 있다.</p>
<p><img src="/hadoop-docker-test-env-hdfs-1.png" alt="Hadoop base 이미지 계층"> <em>그림 1. Hadoop base 이미지 계층 구조. OS → Runtime → App base의 간단한 구조이다.</em></p>
<!-- raw HTML omitted -->
<h2 id="namenode">NameNode</h2>
<p>Java와 Hadoop binary를 가지고 있는 base 이미지를 생성했으니, 이제 NameNode 이미지를 생성해보자.<br>
NameNode 구성시 고려해야할 부분은 다음과 같다.</p>
<ul>
<li>FsImage, EditLog를 저장하는 로컬 파일 시스템 경로</li>
<li>NameNode용 <code>hdfs-site.xml</code> 설정</li>
<li>NameNode 최초 구동 확인 및 네임스페이스 포맷</li>
</ul>
<p>먼저 <code>hdfs-site.xml</code> 파일을 다음과 같이 작성한다.<br>
<code>dfs.namenode.name.dir</code>은 FsImage, EditLog 파일을 저장하는 경로이다. HDFS 파일 블록 크기를 결정하는 <code>dfs.blocksize</code> 항목은 바이트 수로 여기서는 테스트를 위해 기본 값보다 훨씬 작은 10MB로 설정했다. (기본값은 128MB) 이 외의 항목들은 <a href="https://hadoop.apache.org/docs/r2.9.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a> 파일을 참고한다.</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="cp">&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:///opt/hadoop/dfs/name<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.blocksize<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>10485760<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.client.use.datanode.hostname<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-bind-host<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.servicerpc-bind-host<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.http-bind-host<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.https-bind-host<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div><p>시작 스크립트인 <code>start.sh</code>에서는 NameNode의 네임스페이스가 포맷되었는지 확인하고, 포맷되기 전이라면 구동 전 포맷을 먼저 진행해야 한다.<br>
다음과 같이 작성했다.</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh"><span class="cp">#!/bin/bash
</span><span class="cp"></span>
<span class="c1"># 네임스페이스 디렉토리를 입력받아서</span> 
<span class="nv">NAME_DIR</span><span class="o">=</span><span class="nv">$1</span>
<span class="nb">echo</span> <span class="nv">$NAME_DIR</span>

<span class="c1"># 비어있지 않다면 이미 포맷된 것이므로 건너뛰고</span>
<span class="k">if</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="k">$(</span>ls -A <span class="nv">$NAME_DIR</span><span class="k">)</span><span class="s2">&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
  <span class="nb">echo</span> <span class="s2">&#34;NameNode is already formatted.&#34;</span>
<span class="c1"># 비어있다면 포맷을 진행</span>
<span class="k">else</span>
  <span class="nb">echo</span> <span class="s2">&#34;Format NameNode.&#34;</span>
  <span class="nv">$HADOOP_PREFIX</span>/bin/hdfs --config <span class="nv">$HADOOP_CONF_DIR</span> namenode -format
<span class="k">fi</span>

<span class="c1"># NameNode 기동</span>
<span class="nv">$HADOOP_PREFIX</span>/bin/hdfs --config <span class="nv">$HADOOP_CONF_DIR</span> namenode
</code></pre></div><p>Dockerfile은 base 이미지 덕분에 간단하다.</p>
<div class="highlight"><pre class="chroma"><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># 방금 전 로컬에 생성한 base 이미지</span><span class="err">
</span><span class="err"></span><span class="k">FROM</span><span class="s"> hadoop-base:2.9.2</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># NameNode Web UI 응답 여부를 통해 Healthcheck</span><span class="err">
</span><span class="err">HEALTHCHECK --interval=30s --timeout=30s </span>--start-period<span class="o">=</span>5s --retries<span class="o">=</span><span class="m">3</span> CMD curl -f http://localhost:50070/ <span class="o">||</span> <span class="nb">exit</span> <span class="m">1</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># 설정 파일 복제</span><span class="err">
</span><span class="err"></span><span class="k">ADD</span> hdfs-site.xml /etc/hadoop/<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># FsImage, EditLog 파일 경로를 volume으로 연결</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> mkdir /opt/hadoop/dfs/name<span class="err">
</span><span class="err"></span><span class="k">VOLUME</span><span class="s"> /opt/hadoop/dfs/name</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># 실행 스크립트 복제</span><span class="err">
</span><span class="err"></span><span class="k">ADD</span> start.sh /start.sh<span class="err">
</span><span class="err"></span><span class="k">RUN</span> chmod a+x /start.sh<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># NameNode의 HTTP, IPC 포트 노출</span><span class="err">
</span><span class="err"></span><span class="k">EXPOSE</span><span class="s"> 50070 9000</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># 시작 명령어 등록</span><span class="err">
</span><span class="err"></span><span class="k">CMD</span> <span class="p">[</span><span class="s2">&#34;/start.sh&#34;</span><span class="p">,</span> <span class="s2">&#34;/opt/hadoop/dfs/name&#34;</span><span class="p">]</span><span class="err">
</span></code></pre></div><p>이제 이미지를 생성하자. 기본 명령어와 바이너리 파일을 다운로드 받는 등 시간이 오래 걸리는 작업은 이미 base 이미지에서 처리했기 때문에, 그 위에 다시 한번 계층을 쌓는 NameNode는 빌드 시간이 얼마 걸리지 않는 것을 볼 수 있다.</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh"><span class="nb">cd</span> namenode
docker build -t hadoop-namenode:2.9.2 .
</code></pre></div><p>두 개의 이미지가 생성되었고 계층 구조에 하나의 이미지가 더해졌다.</p>
<p><img src="/hadoop-docker-test-env-hdfs-2.png" alt="Hadoop namenode 이미지 계층"></p>
<p>NameNode 이미지를 생성했으니 이제 실제로 기동시켜볼 차례이다. 어차피 DataNode 이미지를 생성하면 docker compose를 구성하는 것이 훨씬 간편하므로 바로 compose 설정 파일을 구성하겠다.</p>
<p>먼저 root 디렉토리에 docker-compose.yml 파일을 생성한다. 디렉토리 구조를 보면 아래와 같다.</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback">.
└── hadoop
    ├── base
    ├── namenode
    ├── datanode
    └── docker-compose.yml
</code></pre></div><p>설정 파일의 내용을 작성한다. <code>services</code>에는 기동할 컨테이너 정보를, <code>volumes</code>에는 마운트할 volume 정보를, <code>networks</code>에는 컨테이너 간 어떤 네트워크 구성을 사용할지 지정하는 항목이다.<br>
<code>volumes</code> 이하에 정의된 각 항목은 다음과 같은 의미를 갖고 있다.</p>
<ul>
<li><code>namenode:/opt/hadoop/dfs/name</code>: <code>namenode</code> volume을 컨테이너의 <code>/opt/hadoop/dfs/name</code> 경로에 마운트</li>
<li><code>/tmp:/tmp</code>: 컨테이너가 기동되는 호스트의 <code>/tmp</code> 경로를 컨테이너의 <code>/tmp</code> 경로로 마운트. 호스트와 컨테이너 간 파일을 쉽게 공유하기 위해서 지정함</li>
</ul>
<p>콜론으로 구분된 설정 값의 뒷 부분이 컨테이너에 해당한다는 것을 기억하면 쉽게 이해할 수 있다.</p>
<div class="highlight"><pre class="chroma"><code class="language-yml" data-lang="yml"><span class="k">version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;3&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">services</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">namenode</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="k">image</span><span class="p">:</span><span class="w"> </span>hadoop-namenode<span class="p">:</span><span class="m">2.9.2</span><span class="w">
</span><span class="w">    </span><span class="k">container_name</span><span class="p">:</span><span class="w"> </span>namenode<span class="w">
</span><span class="w">    </span><span class="k">hostname</span><span class="p">:</span><span class="w"> </span>namenode<span class="w">
</span><span class="w">    </span><span class="k">ports</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="s2">&#34;50070:50070&#34;</span><span class="w">
</span><span class="w">      </span>- <span class="s2">&#34;9000:9000&#34;</span><span class="w">
</span><span class="w">    </span><span class="k">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- namenode<span class="p">:</span>/opt/hadoop/dfs/name<span class="w">
</span><span class="w">      </span>- /tmp<span class="p">:</span>/tmp<span class="w">
</span><span class="w">    </span><span class="k">networks</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- bridge<span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">namenode</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">networks</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">bridge</span><span class="p">:</span><span class="w">
</span></code></pre></div><p>이제 이 설정 파일을 바탕으로 NameNode 컨테이너를 기동할 수 있다.</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh"><span class="c1"># docker-compose.yml 파일이 위치한 경로로 이동</span>
<span class="nb">cd</span> hadoop

<span class="c1"># 컨테이너를 백그라운드에서 실행</span>
<span class="c1">#  종료할 때에는 docker-compose down</span>
docker-compose up -d
Creating namenode        ... <span class="k">done</span>

<span class="c1"># 기동중인 컨테이너 프로세스 확인</span>
docker ps
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS                            PORTS               622e4f642435
hadoop-namenode:2.9.2          <span class="s2">&#34;/start.sh /opt/hado…&#34;</span>   <span class="m">10</span> seconds ago      Up <span class="m">6</span> seconds <span class="o">(</span>health: starting<span class="o">)</span>   0.0.0.0.:9000-&gt;9000/tcp, 0.0.0.0.:50070-&gt;50070/tcp 

<span class="c1"># 생성된 bridge 네트워크 확인</span>
docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
0d9989bd9f78        bridge              bridge              <span class="nb">local</span>
9ae1ae84360f        hadoop_bridge       bridge              <span class="nb">local</span>
62a94ebd58b7        host                host                <span class="nb">local</span>

<span class="c1"># 생성된 volume 확인</span>
docker volume ls
DRIVER              VOLUME NAME
<span class="nb">local</span>               hadoop_namenode

<span class="c1"># namenode 컨테이너의 로그 확인</span>
docker logs -f namenode
</code></pre></div><p>docker compose로 기동한 후 마지막 명령어로 로그를 살펴보면, 네임스페이스를 포맷한 로그와 NameNode를 기동한 로그를 확인할 수 있다.<br>
브라우저에서 http://localhost:50070 으로 접속하면 아래와 같은 NameNode Web UI에 접근한다.</p>
<p><img src="/hadoop-docker-test-env-hdfs-3.png" alt="NameNode Web UI"></p>
<p>또한 NameNode가 기동되었으니, 아직 DataNode를 띄우지 않더라도 폴더의 생성과 삭제, 그리고 파일 목록 조회가 가능하다.<br>
NameNode 컨테이너 내부에 있는 Hadoop 클라이언트를 실행해서 테스트해보자.</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh"><span class="c1"># namenode 이름의 컨테이너의 hadoop 클라이언트를 실행. 파일 시스템의 root 디렉토리를 모두 조회한다.</span>
docker <span class="nb">exec</span> namenode /opt/hadoop/bin/hadoop fs -ls -R /

<span class="c1"># 명령어 등록</span>
<span class="nb">alias</span> <span class="nv">hadoop</span><span class="o">=</span><span class="s2">&#34;docker exec namenode /opt/hadoop/bin/hadoop&#34;</span>

<span class="c1"># 폴더 생성/조회/삭제</span>
hadoop fs -mkdir -p /tmp/test/app
hadoop fs -ls -R /tmp
hadoop fs -rm -r /tmp/test/app
</code></pre></div><p><code>docker exec [컨테이너 이름] [명령어]</code>를 입력하면 동작 중인 컨테이너 내에서 <code>[명령어]</code>에 해당하는 명령어를 실행한 결과의 표준 출력을 현재 쉘에 출력한다.<br>
컨테이너 내 자주 실행하는 프로그램응 <code>alias</code>로 등록해두면 편리하다. 여기에서는 NameNode의 <code>bin/hadoop</code> 프로그램을 <code>hadoop</code>으로 alias 지정했다.</p>
<h2 id="datanode">DataNode</h2>
<p>먼저 작성했던 JVM과 하둡 바이너리를 포함하는 base 이미지로부터 DataNode 이미지를 생성해보자. 고려해야할 부분은 두 가지이다.</p>
<ul>
<li>파일 블록을 저장하는 로컬 파일 시스템 경로</li>
<li>DataNode용 <code>hdfs-site.xml</code> 설정<br>
파일 블록 저장 경로는 <code>$HADOOP_PREFIX/dfs/data</code>로 설정할 것이다. 이 내용은 <code>hdfs-site.xml</code> 파일을 <code>datanode</code> 디렉토리 이하에 생성하고 내용을 다음과 같이 작성한다.</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:///opt/hadoop/dfs/data<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.blocksize<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>10485760<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>  
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.datanode.use.datanode.hostname<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div><p>시작 스크립트는 <code>start.sh</code>에 다음과 같이 작성한다.</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh"><span class="cp">#!/bin/sh
</span><span class="cp"></span>
<span class="nv">$HADOOP_PREFIX</span>/bin/hdfs --config <span class="nv">$HADOOP_CONF_DIR</span> datanode
</code></pre></div><p><code>hdfs</code> 프로그램을 <code>datanode</code> 옵션으로 시작하면 DataNode 프로세스가 기동한다.</p>
<p>마지막으로 Dockerfile 이다. <code>HEALTHCHECK</code>에 Web UI 주소가 입력된 것과 <code>EXPOSE</code>에 명시한 포트를 눈여겨 본다.</p>
<div class="highlight"><pre class="chroma"><code class="language-dockerfile" data-lang="dockerfile"><span class="k">FROM</span><span class="s"> hadoop-base:2.9.2</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># DataNode Web UI 응답 여부를 통해 Healthcheck</span><span class="err">
</span><span class="err">HEALTHCHECK --interval=30s --timeout=30s </span>--start-period<span class="o">=</span>5s --retries<span class="o">=</span><span class="m">3</span>  CMD curl -f http://localhost:50075/ <span class="o">||</span> <span class="nb">exit</span> <span class="m">1</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> mkdir /opt/hadoop/dfs/data<span class="err">
</span><span class="err"></span><span class="k">VOLUME</span><span class="s"> /opt/hadoop/dfs/data</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">ADD</span> start.sh /start.sh<span class="err">
</span><span class="err"></span><span class="k">RUN</span> chmod a+x /start.sh<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># WebUI, 데이터전송</span><span class="err">
</span><span class="err"></span><span class="k">EXPOSE</span><span class="s"> 50075 50010</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">CMD</span> <span class="p">[</span><span class="s2">&#34;/start.sh&#34;</span><span class="p">]</span><span class="err">
</span></code></pre></div><p>NameNode 이미지를 구성할 때와 크게 다르지 않다. 이제 생성한 파일들을 가지고 이미지를 생성한다.</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh"><span class="nb">cd</span> datanode
docker build -t hadoop-datanode:2.9.2 .
</code></pre></div><p>이제 컨테이너 실행 환경 정보를 담고 있는 <code>docker-compose.yml</code> 파일에 DataNode를 추가한다. 로컬 환경이지만 세 개의 DataNode를 띄울 것이다.</p>
<div class="highlight"><pre class="chroma"><code class="language-yml" data-lang="yml"><span class="k">version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;3.4&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># 이미지와 네트워크 정보에 대한 base service를 지정</span><span class="w">
</span><span class="w"></span><span class="k">x-datanode_base</span><span class="p">:</span><span class="w"> </span><span class="cp">&amp;datanode_base</span><span class="w">
</span><span class="w">  </span><span class="k">image</span><span class="p">:</span><span class="w"> </span>hadoop-datanode<span class="p">:</span><span class="m">2.9.2</span><span class="w">
</span><span class="w">  </span><span class="k">networks</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- bridge<span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">services</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">namenode</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="k">image</span><span class="p">:</span><span class="w"> </span>hadoop-namenode<span class="p">:</span><span class="m">2.9.2</span><span class="w">
</span><span class="w">    </span><span class="k">container_name</span><span class="p">:</span><span class="w"> </span>namenode<span class="w">
</span><span class="w">    </span><span class="k">hostname</span><span class="p">:</span><span class="w"> </span>namenode<span class="w">
</span><span class="w">    </span><span class="k">ports</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="m">50070</span><span class="p">:</span><span class="m">50070</span><span class="w">
</span><span class="w">      </span>- <span class="m">9000</span><span class="p">:</span><span class="m">9000</span><span class="w">
</span><span class="w">    </span><span class="k">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- namenode<span class="p">:</span>/opt/hadoop/dfs/name<span class="w">
</span><span class="w">      </span>- /tmp<span class="p">:</span>/tmp<span class="w">
</span><span class="w">    </span><span class="k">networks</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- bridge<span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="k">datanode01</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="k">&lt;&lt;</span><span class="p">:</span><span class="w"> </span><span class="cp">*datanode_base</span><span class="w">
</span><span class="w">    </span><span class="k">container_name</span><span class="p">:</span><span class="w"> </span>datanode01<span class="w">
</span><span class="w">    </span><span class="k">hostname</span><span class="p">:</span><span class="w"> </span>datanode01<span class="w">
</span><span class="w">    </span><span class="k">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- datanode01<span class="p">:</span>/opt/hadoop/dfs/data<span class="w">
</span><span class="w">  
</span><span class="w">  </span><span class="k">datanode02</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="k">&lt;&lt;</span><span class="p">:</span><span class="w"> </span><span class="cp">*datanode_base</span><span class="w">
</span><span class="w">    </span><span class="k">container_name</span><span class="p">:</span><span class="w"> </span>datanode02<span class="w">
</span><span class="w">    </span><span class="k">hostname</span><span class="p">:</span><span class="w"> </span>datanode02<span class="w">
</span><span class="w">    </span><span class="k">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- datanode02<span class="p">:</span>/opt/hadoop/dfs/data<span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="k">datanode03</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="k">&lt;&lt;</span><span class="p">:</span><span class="w"> </span><span class="cp">*datanode_base</span><span class="w">
</span><span class="w">    </span><span class="k">container_name</span><span class="p">:</span><span class="w"> </span>datanode03<span class="w">
</span><span class="w">    </span><span class="k">hostname</span><span class="p">:</span><span class="w"> </span>datanode03<span class="w">
</span><span class="w">    </span><span class="k">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- datanode03<span class="p">:</span>/opt/hadoop/dfs/data<span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">namenode</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">datanode01</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">datanode02</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">datanode03</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">networks</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">bridge</span><span class="p">:</span><span class="w">
</span></code></pre></div><p>파일을 수정하고 <code>docker-compose up -d</code>를 다시 실행하면 세 개의 DataNode 컨테이너를 추가로 띄우게 된다. DataNode는 NameNode로 heartbeat을 보내면서 NameNode에 등록된다.</p>
<p>NameNode</p>
<h2 id="proxy">Proxy</h2>
<hr>
<p>이어지는 포스팅에서는 HDFS 파일을 읽고 쓰는 예제와 Proxy 구성을 통해 로컬 환경에서 reverse proxy로 서로 다른 DataNode 컨테이너의 Web UI에 접근하는 방법을 설명할 예정이다.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Docker 공식 홈페이지의 <a href="https://www.docker.com/resources/what-container">What is a Container?</a>를 참고한다. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>이 글을 작성하는 시점의 Hadoop 2 최신 버전인 2.9.2 버전의 공식 문서를 참고했다. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>그 외 지원 버전은 Hadoop confluence 페이지의 <a href="https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions">Hadoop Java Versions</a>를 참고한다. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

  </div>

  
    <div id="sub-header">
      Updated 24 September 2019
    </div>
  

  <div id="links">
    
      <a class="basic-alignment left" href="https://blog.geunho.dev/posts/mac-terminal-text-edit/">&laquo; Mac Terminal에서 텍스트 편집기 바로 열기</a>
    
    
      <a class="basic-alignment left" href="https://blog.geunho.dev/posts/container-based-test-env/">Testcontainers - 컨테이너 기반 테스트 환경 &raquo;</a>
    
  </div>
</section>
<section id="comment">
  <script src="https://utteranc.es/client.js"
    repo="geunho/blog"
    issue-term="title"
    theme="github-light"
    crossorigin="anonymous"
    async>
  </script>  
</section>

<footer>
  <div>
    <p>
    &copy; 2013-2020 Copyright Geunho Kim. All rights reserved.
    </p>
  </div>
</footer>

